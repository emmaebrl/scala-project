# Scala Spark Template

Template modulaire en Scala pour lire, transformer et Ã©crire des donnÃ©es avec Apache Spark.

## ğŸš€ FonctionnalitÃ©s

- Lecture automatique de fichiers CSV, Parquet ou tables Hive
- Traitement de donnÃ©es configurable par types de rapports (`report1`, etc.)
- Ã‰criture des rÃ©sultats configurÃ©e via un fichier `.properties`
- Compatible avec Spark local ou cluster

---

## â–¶ï¸ ExÃ©cution

### ğŸ“„ TÃ©lÃ©charger le fichier JAR depuis GitHub

TÃ©lÃ©charge le fichier `scala-project-1.3.2-jar-with-dependencies.jar` depuis :  
ğŸ‘‰ [https://github.com/emmaebrl/scala-project/packages/2457639](https://github.com/emmaebrl/scala-project/packages/2457639)

---

### â–¶ï¸ Lancer le projet avec `java -cp`

Une fois le JAR tÃ©lÃ©chargÃ©, exÃ©cute la commande suivante :

```bash
java -cp scala-project-1.3.2-jar-with-dependencies.jar fr.mosef.scala.template.Main \
  <master-url> \
  <input-path> \
  <output-path> \
  <report1,report2,...> \
  [optional-config-path]
```

## ğŸ§¾ ParamÃ¨tres CLI

| Position | Nom           | Obligatoire | Description                                                                 |
|----------|----------------|-------------|-----------------------------------------------------------------------------|
| `0`      | `MASTER_URL`   | âŒ           | URL du cluster Spark. Exemples : `local[2]`, `yarn`. Par dÃ©faut : `local[1]`. |
| `1`      | `SRC_PATH`     | âœ…           | Chemin d'entrÃ©e des donnÃ©es : `.csv`, `.parquet`, ou `hive:nom_table`.       |
| `2`      | `DST_PATH`     | âŒ           | Dossier de sortie pour les rapports. Par dÃ©faut : `./default/output-writer`. |
| `3`      | `REPORT_TYPES` | âŒ           | Liste des types de rapports Ã  gÃ©nÃ©rer (sÃ©parÃ©s par des virgules). Par dÃ©faut : `report1`. |
| `4`      | `CONFIG_PATH`  | âŒ           | Chemin d'un fichier `.properties` de configuration. Par dÃ©faut : `application.properties` en ressources. |


âœ… Exemples
**Exemple avec CSV et config externe :**
```bash
spark-submit \
--class fr.mosef.scala.template.Main \
--master local[2] \
./scala-template.jar \
local[2] \
./data/input.csv \
./data/output \
report1,report2 \
./config/application.properties
```

**Exemple avec table Hive :**
```bash
spark-submit \
--class fr.mosef.scala.template.Main \
--master yarn \
./scala-template.jar \
yarn \
hive:ma_table_hive \
/hdfs/output \
report1
```

**Exemple minimal :**
```bash
spark-submit \
--class fr.mosef.scala.template.Main \
./scala-template.jar \
local[2] \
./data/input.csv
```

**ğŸ›  Structure du projet**
```text
src/
â”œâ”€â”€ main/
â”‚   â”œâ”€â”€ scala/
â”‚   â”‚   â””â”€â”€ fr/mosef/scala/template/
â”‚   â”‚       â”œâ”€â”€ Main.scala
â”‚   â”‚       â”œâ”€â”€ processor/
â”‚   â”‚       â”‚   â”œâ”€â”€ Processor.scala
â”‚   â”‚       â”‚   â””â”€â”€ impl/ProcessorImpl.scala
â”‚   â”‚       â”œâ”€â”€ reader/
â”‚   â”‚       â”‚   â”œâ”€â”€ Reader.scala
â”‚   â”‚       â”‚   â””â”€â”€ impl/ReaderImpl.scala
â”‚   â”‚       â””â”€â”€ writer/Writer.scala
â”‚   â””â”€â”€ resources/
â”‚       â””â”€â”€ application.properties
```

**ğŸ“„ Exemple application.properties**
```text
properties
format=parquet
header=true
mode=overwrite
coalesce=true
```
